{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from git_lit import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file fonts/ArchitectsDaughter.ttf due to UnicodeDecodeError\n",
      "Skipping file fonts/KGNeatlyPrinted.ttf due to UnicodeDecodeError\n",
      "https://github.com/e-johnstonn/FableForge 5224\n",
      "Skipping file media/inference-demo.mp4 due to UnicodeDecodeError\n",
      "https://github.com/abacaj/mpt-30B-inference 2183\n",
      "https://github.com/eric-mitchell/direct-preference-optimization 17166\n",
      "Skipping file data/conf_mat.eps due to UnicodeDecodeError\n",
      "Skipping file data/conf_mat_yolo.eps due to UnicodeDecodeError\n",
      "Skipping file demo/Demo-Clip.mp4 due to UnicodeDecodeError\n",
      "Skipping file demo/Demo-Full.mp4 due to UnicodeDecodeError\n",
      "Skipping file weights/classes5.h5 due to UnicodeDecodeError\n",
      "Skipping file weights/classes8.h5 due to UnicodeDecodeError\n",
      "Skipping file weights/solo.h5 due to UnicodeDecodeError\n",
      "Skipping file weights/yolo.h5 due to UnicodeDecodeError\n",
      "https://github.com/pentilm/AirCtrl 28716\n",
      "https://github.com/automorphic-ai/aegis 2537\n",
      "Skipping file openAI/__pycache__/controller.cpython-310.pyc due to UnicodeDecodeError\n",
      "Skipping file openAI/__pycache__/controller.cpython-39.pyc due to UnicodeDecodeError\n",
      "Skipping file sgrep/__pycache__/controller.cpython-310.pyc due to UnicodeDecodeError\n",
      "Skipping file sgrep/__pycache__/controller.cpython-39.pyc due to UnicodeDecodeError\n",
      "https://github.com/JetP1ane/Callisto 3942\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generate\u001b[39m.\u001b[39;49msearch_for_repo(last_n_days\u001b[39m=\u001b[39;49m\u001b[39m14\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\git_lit\\generate.py:82\u001b[0m, in \u001b[0;36msearch_for_repo\u001b[1;34m(n_repos, last_n_days)\u001b[0m\n\u001b[0;32m     79\u001b[0m repo_data[key][\u001b[39m\"\u001b[39m\u001b[39mwrite_date\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m repo_data[key][\u001b[39m\"\u001b[39m\u001b[39marticle_publish_date\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m repo_content \u001b[39m=\u001b[39m get_repo_content(\n\u001b[0;32m     83\u001b[0m     user\u001b[39m=\u001b[39;49mrepo[\u001b[39m\"\u001b[39;49m\u001b[39mowner\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mlogin\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     84\u001b[0m     repo\u001b[39m=\u001b[39;49mrepo[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     85\u001b[0m )\n\u001b[0;32m     86\u001b[0m repo_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m     87\u001b[0m     [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mcontent\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m path, content \u001b[39min\u001b[39;00m repo_content\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     89\u001b[0m num_tokens \u001b[39m=\u001b[39m num_tokens_from_string(repo_str, \u001b[39m\"\u001b[39m\u001b[39mcl100k_base\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\git_lit\\generate.py:45\u001b[0m, in \u001b[0;36mget_repo_content\u001b[1;34m(user, repo, path)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m repo_repsone\u001b[39m.\u001b[39mjson():\n\u001b[0;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdir\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m         files_dict\u001b[39m.\u001b[39mupdate(get_repo_content(user, repo, file[\u001b[39m\"\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[0;32m     47\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(file[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mendswith(ext) \u001b[39mfor\u001b[39;00m ext \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mEXCLUDE_EXTENSIONS):\n\u001b[0;32m     48\u001b[0m         \u001b[39mif\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39mdownload_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\git_lit\\generate.py:45\u001b[0m, in \u001b[0;36mget_repo_content\u001b[1;34m(user, repo, path)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m repo_repsone\u001b[39m.\u001b[39mjson():\n\u001b[0;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdir\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m         files_dict\u001b[39m.\u001b[39mupdate(get_repo_content(user, repo, file[\u001b[39m\"\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[0;32m     47\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(file[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mendswith(ext) \u001b[39mfor\u001b[39;00m ext \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mEXCLUDE_EXTENSIONS):\n\u001b[0;32m     48\u001b[0m         \u001b[39mif\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39mdownload_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\git_lit\\generate.py:45\u001b[0m, in \u001b[0;36mget_repo_content\u001b[1;34m(user, repo, path)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m repo_repsone\u001b[39m.\u001b[39mjson():\n\u001b[0;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdir\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m         files_dict\u001b[39m.\u001b[39mupdate(get_repo_content(user, repo, file[\u001b[39m\"\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[0;32m     47\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(file[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mendswith(ext) \u001b[39mfor\u001b[39;00m ext \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mEXCLUDE_EXTENSIONS):\n\u001b[0;32m     48\u001b[0m         \u001b[39mif\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39mdownload_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\git_lit\\generate.py:50\u001b[0m, in \u001b[0;36mget_repo_content\u001b[1;34m(user, repo, path)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m file[\u001b[39m\"\u001b[39m\u001b[39mdownload_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m file_response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(file[\u001b[39m\"\u001b[39;49m\u001b[39mdownload_url\u001b[39;49m\u001b[39m\"\u001b[39;49m], headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m     51\u001b[0m file_response\u001b[39m.\u001b[39mraise_for_status()\n\u001b[0;32m     53\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\requests\\sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[1;32m--> 747\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[0;32m    749\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\urllib3\\response.py:940\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    939\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[0;32m    942\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[0;32m    943\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\urllib3\\response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m amt:\n\u001b[0;32m    877\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer\u001b[39m.\u001b[39mget(amt)\n\u001b[1;32m--> 879\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[0;32m    881\u001b[0m flush_decoder \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\urllib3\\response.py:814\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    811\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    813\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 814\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[0;32m    816\u001b[0m         \u001b[39m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    817\u001b[0m         \u001b[39m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    822\u001b[0m         \u001b[39m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m         \u001b[39m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\voyno\\Desktop\\code\\repos\\GitLit\\venv\\lib\\site-packages\\urllib3\\response.py:799\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1270\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1271\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1272\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1273\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1275\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1128\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1130\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate.search_for_repo(last_n_days=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file fonts/ArchitectsDaughter.ttf due to UnicodeDecodeError\n",
      "Skipping file fonts/KGNeatlyPrinted.ttf due to UnicodeDecodeError\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "repo_content = generate.get_repo_content('e-johnstonn', 'FableForge')\n",
    "repo_str = \"\\n\\n\".join(\n",
    "    [f\"{path}\\n\\n{content}\" for path, content in repo_content.items()]\n",
    ")\n",
    "response = generate.generate_article(repo_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# FableForge: An Open Source Project for Generating Picture Books\n",
       "\n",
       "FableForge is an open source project that uses artificial intelligence to generate picture books from a single prompt. The project utilizes OpenAI's new function calling, Replicate's API for Stable Diffusion, and Deep Lake for storing generated images and corresponding prompts. This article will take a deep dive into the project, explaining its functionality, setup, and potential improvements.\n",
       "\n",
       "## Project Overview\n",
       "\n",
       "FableForge is built with LangChain, Deep Lake, and Replicate. The project generates a picture book from a single prompt using OpenAI's new function calling and Replicate's API for Stable Diffusion. The generated images and corresponding prompts are stored in Deep Lake. \n",
       "\n",
       "The project is licensed under the MIT License, which allows anyone to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software.\n",
       "\n",
       "## Installation and Setup\n",
       "\n",
       "To install FableForge, you need to clone the repository and install the requirements specified in the `requirements.txt` file. You also need to set up your OpenAI and Replicate API keys in `keys.env`. \n",
       "\n",
       "If you want to save your images and prompts, you need to set up your Activeloop Deep Lake token and dataset path in `keys.env`. After setting up, you can run `streamlit run main.py` to start the app.\n",
       "\n",
       "## Deep Lake Setup\n",
       "\n",
       "Deep Lake is used to store the generated pictures and prompts in the cloud. It makes it easy to work with multiple modalities of data (image/text), and displays them in a web UI. To set this up, you need to create an account on the Deep Lake website and get an API token and dataset link. \n",
       "\n",
       "## Replicate Setup\n",
       "\n",
       "A Replicate API key is necessary for this app. You can get one by creating an account on the Replicate website. Replicate provides free image generation for new users.\n",
       "\n",
       "## Architecture\n",
       "\n",
       "The architecture of FableForge is designed to be straightforward and efficient. It uses a combination of OpenAI's GPT-3, Replicate's Stable Diffusion, and Deep Lake's data storage capabilities to generate and store picture books.\n",
       "\n",
       "## Improvements\n",
       "\n",
       "The current demo uses Replicate for image generation due to its ease of use. However, it can be connected to your own Stable Diffusion setup (local or cloud-based) for better results. The project recommends some combination of Diffusers and FastAPI as a starting point.\n",
       "\n",
       "## Code Review\n",
       "\n",
       "The codebase of FableForge is well-structured and organized. It includes a `.gitignore` file to ignore unnecessary files and folders, a `LICENSE` file for the MIT License, and a `README.md` file for project documentation.\n",
       "\n",
       "The main logic of the project is contained in `api_utils.py`, `deep_lake_utils.py`, `main.py`, and `pdf_gen_utils.py`. \n",
       "\n",
       "`api_utils.py` contains the `BuildBook` class which handles the generation of the book text and images. \n",
       "\n",
       "`deep_lake_utils.py` contains the `SaveToDeepLake` class which handles saving the generated images and prompts to Deep Lake.\n",
       "\n",
       "`main.py` is the main script that runs the Streamlit app and handles user input.\n",
       "\n",
       "`pdf_gen_utils.py` contains functions for generating the final PDF of the picture book.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "FableForge is an innovative open source project that leverages the power of AI to generate picture books. It provides a great example of how AI can be used in creative and educational applications. Whether you're a developer looking to contribute to an open source project, an educator looking for new teaching tools, or just a tech enthusiast interested in AI, FableForge is worth checking out."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file fonts/ArchitectsDaughter.ttf due to UnicodeDecodeError\n",
      "Skipping file fonts/KGNeatlyPrinted.ttf due to UnicodeDecodeError\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "repo_content = generate.get_repo_content('e-johnstonn', 'FableForge')\n",
    "repo_str = \"\\n\\n\".join(\n",
    "    [f\"{path}\\n\\n{content}\" for path, content in repo_content.items()]\n",
    ")\n",
    "response = generate.generate_article(repo_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# FableForge: An Open Source Project for Generating Picture Books\n",
       "\n",
       "FableForge is an innovative open source project that uses artificial intelligence to generate picture books from a single prompt. The project leverages the power of OpenAI's new function calling, Replicate's API for Stable Diffusion, and Deep Lake for storing generated images and corresponding prompts. This article will take a deep dive into the architecture of FableForge, its pros and cons, and the main tools/packages/dependencies used in the project.\n",
       "\n",
       "## Architecture\n",
       "\n",
       "FableForge's architecture is designed to be efficient and scalable. The project is built with LangChain, Deep Lake, and Replicate. The architecture diagram shows the flow of data and the interaction between different components of the project.\n",
       "\n",
       "The process starts with the user inputting a prompt. The prompt is then processed by the OpenAI model to generate the text for the book. The generated text is then passed to the Replicate API, which generates images based on the text. The images and corresponding prompts are then stored in Deep Lake.\n",
       "\n",
       "The architecture is designed in such a way that it can handle multiple requests concurrently. It uses ThreadPoolExecutor for parallel processing, which significantly improves the performance of the application.\n",
       "\n",
       "## Pros and Cons\n",
       "\n",
       "### Pros\n",
       "\n",
       "1. **Innovative Use of AI:** FableForge creatively uses AI to generate picture books. This opens up new possibilities for content creation.\n",
       "\n",
       "2. **Scalability:** The use of ThreadPoolExecutor for parallel processing makes the application highly scalable.\n",
       "\n",
       "3. **Ease of Use:** The application is easy to use. Users only need to input a prompt, and the application generates a picture book based on the prompt.\n",
       "\n",
       "4. **Open Source:** Being an open source project, FableForge allows developers to contribute to the project and learn from it.\n",
       "\n",
       "### Cons\n",
       "\n",
       "1. **Dependence on External APIs:** The application relies heavily on external APIs like OpenAI and Replicate. Any changes or issues with these APIs can affect the functionality of the application.\n",
       "\n",
       "2. **Limited Customization:** The application currently supports a limited number of styles for the picture books. More styles could be added to enhance the user experience.\n",
       "\n",
       "## Main Tools/Packages/Dependencies\n",
       "\n",
       "### OpenAI\n",
       "\n",
       "OpenAI's API is used to generate the text for the picture books. The API supports a variety of models and provides powerful capabilities for natural language processing.\n",
       "\n",
       "### Replicate\n",
       "\n",
       "Replicate's API is used to generate images based on the generated text. The API supports Stable Diffusion, which is a method for generating high-quality images.\n",
       "\n",
       "### Deep Lake\n",
       "\n",
       "Deep Lake is used to store the generated images and corresponding prompts. It provides an easy way to work with multiple modalities of data and displays them in a web UI.\n",
       "\n",
       "### LangChain\n",
       "\n",
       "LangChain is used to handle the interaction with the OpenAI API. It provides a convenient way to send requests to the API and process the responses.\n",
       "\n",
       "### Streamlit\n",
       "\n",
       "Streamlit is used to create the web interface for the application. It allows for rapid prototyping and development of web applications.\n",
       "\n",
       "### Python's Concurrent.Futures\n",
       "\n",
       "Python's concurrent.futures module provides a high-level interface for asynchronously executing callables. The module uses ThreadPoolExecutor for parallel processing, which significantly improves the performance of the application.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "FableForge is a fascinating open source project that showcases the power of AI in content creation. The project provides a great learning opportunity for developers interested in AI, image generation, and web development. Despite its reliance on external APIs and limited customization options, FableForge stands out for its innovative use of AI, scalability, and ease of use."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file fonts/ArchitectsDaughter.ttf due to UnicodeDecodeError\n",
      "Skipping file fonts/KGNeatlyPrinted.ttf due to UnicodeDecodeError\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "repo_content = generate.get_repo_content('e-johnstonn', 'FableForge')\n",
    "repo_str = \"\\n\\n\".join(\n",
    "    [f\"{path}\\n\\n{content}\" for path, content in repo_content.items()]\n",
    ")\n",
    "response = generate.generate_article(repo_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# FableForge: A Deep Dive into Generating Picture Books with OpenAI and Replicate\n",
       "\n",
       "FableForge is an open-source project that leverages the power of OpenAI and Replicate to generate picture books from a single prompt. It's an exciting project that combines the capabilities of AI and image generation to create a unique and interactive experience. In this article, we'll take a deep dive into the project, exploring its architecture, the tools it uses, and how you can contribute to its development.\n",
       "\n",
       "## System Design and Architecture\n",
       "\n",
       "FableForge is designed as a Streamlit application, which allows for a user-friendly interface where users can input a prompt and generate a picture book. The application uses OpenAI's GPT-3 model to generate the text for the book and Replicate's API for Stable Diffusion to generate the images. The generated images and corresponding prompts are stored in Deep Lake, a cloud-based storage solution.\n",
       "\n",
       "The project is structured into several Python files, each responsible for a specific functionality:\n",
       "\n",
       "- `main.py`: This is the entry point of the application. It handles user inputs and controls the flow of the application.\n",
       "- `api_utils.py`: This file contains the `BuildBook` class, which is responsible for generating the book text and images.\n",
       "- `deep_lake_utils.py`: This file contains the `SaveToDeepLake` class, which is responsible for saving the generated images and prompts to Deep Lake.\n",
       "- `pdf_gen_utils.py`: This file contains functions for creating the final PDF of the picture book.\n",
       "- `prompts.py`: This file contains the prompts used by the OpenAI model to generate the book text.\n",
       "\n",
       "## Key Tools and Packages\n",
       "\n",
       "FableForge uses several open-source tools and packages to achieve its functionality:\n",
       "\n",
       "- **OpenAI**: The project uses OpenAI's GPT-3 model to generate the text for the picture book. The model is fed a prompt and generates a story based on it.\n",
       "\n",
       "- **Replicate**: Replicate's API for Stable Diffusion is used to generate the images for the book. The API takes a prompt and generates an image based on it.\n",
       "\n",
       "- **Deep Lake**: Deep Lake is used to store the generated images and prompts. It provides a convenient way to store and manage the data generated by the application.\n",
       "\n",
       "- **Streamlit**: Streamlit is used to create the user interface for the application. It allows for easy creation of interactive web applications.\n",
       "\n",
       "- **ReportLab**: ReportLab is used to generate the final PDF of the picture book. It provides a powerful set of tools for creating complex PDF documents.\n",
       "\n",
       "## Contributing to FableForge\n",
       "\n",
       "FableForge is an open-source project and welcomes contributions from the community. Here are a few ways you can contribute:\n",
       "\n",
       "- **Improve the Image Generation**: The current implementation uses Replicate for image generation. You could contribute by connecting it to your own Stable Diffusion setup for better results.\n",
       "\n",
       "- **Add More Styles**: The application currently supports a limited number of styles for the picture book. You could contribute by adding more styles.\n",
       "\n",
       "- **Improve the User Interface**: While the current Streamlit interface is functional, there's always room for improvement. You could contribute by improving the user interface.\n",
       "\n",
       "- **Bug Fixes and Performance Improvements**: As with any software project, there are likely to be bugs and performance issues. You could contribute by fixing these issues and improving the performance of the application.\n",
       "\n",
       "## Similar Projects\n",
       "\n",
       "If you're interested in FableForge, you might also want to check out similar projects like:\n",
       "\n",
       "- **DeepArt.io**: This is a web application that uses AI to turn your photos into art.\n",
       "- **Runway ML**: This is a creative toolkit powered by machine learning that allows creators to use AI in their projects.\n",
       "- **Artbreeder**: This is a platform that uses AI to combine images and create new visuals.\n",
       "\n",
       "In conclusion, FableForge is an exciting project that showcases the power of AI in creative applications. Whether you're a developer interested in contributing to the project or a user looking to generate your own picture book, FableForge offers a unique and engaging experience."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file fonts/ArchitectsDaughter.ttf due to UnicodeDecodeError\n",
      "Skipping file fonts/KGNeatlyPrinted.ttf due to UnicodeDecodeError\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "repo_content = generate.get_repo_content('e-johnstonn', 'FableForge')\n",
    "repo_str = \"\\n\\n\".join(\n",
    "    [f\"{path}\\n\\n{content}\" for path, content in repo_content.items()]\n",
    ")\n",
    "response = generate.generate_article(repo_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# FableForge: An Open Source Project for Generating Picture Books\n",
       "\n",
       "FableForge is an open source project that uses artificial intelligence to generate picture books from a single prompt. This project is built with LangChain, Deep Lake, and Replicate, and it leverages OpenAI's new function calling and Replicate's API for Stable Diffusion. This article will take a deep dive into the project, explaining its software architecture, the tools/packages used, and how it can be extrapolated to adjacent projects and work streams.\n",
       "\n",
       "## System Design and Software Architecture\n",
       "\n",
       "FableForge is designed to be a standalone application that can be run locally. The main components of the system are:\n",
       "\n",
       "1. **OpenAI's GPT-3.5-turbo model**: This model is used to generate the text for the picture book. The model takes a prompt from the user and generates a 3-6 page children's picture book. Each page contains 2-3 sentences and the text is formatted to include a title and page numbers.\n",
       "\n",
       "2. **Replicate's API for Stable Diffusion**: This API is used to generate images for each page of the book. The images are generated based on the text from the GPT-3.5-turbo model.\n",
       "\n",
       "3. **Deep Lake**: This is used to store the generated images and corresponding prompts in the cloud. It makes it easy to work with multiple modalities of data (image/text) and displays them in a web UI.\n",
       "\n",
       "4. **Streamlit**: This is used to create the user interface for the application. The user can enter a prompt, select a style for the picture book, and choose a model to use. The user can also choose to save the generated book to Deep Lake.\n",
       "\n",
       "## Critical Tools and Packages\n",
       "\n",
       "Several tools and packages are used in this project. Here are some of the most critical ones:\n",
       "\n",
       "1. **dotenv**: This package is used to load environment variables from a `.env` file. These variables include the OpenAI and Replicate API keys, and the Deep Lake token and dataset path.\n",
       "\n",
       "2. **streamlit**: This package is used to create the user interface for the application. It provides functions for creating text inputs, select boxes, radio buttons, checkboxes, and buttons.\n",
       "\n",
       "3. **concurrent.futures**: This module provides a high-level interface for asynchronously executing callables. It is used to generate the prompts and images for the book in parallel, which significantly speeds up the generation process.\n",
       "\n",
       "4. **requests**: This package is used to download the generated images from the URLs returned by the Replicate API.\n",
       "\n",
       "5. **PyPDF2 and reportlab**: These packages are used to create the PDF file for the picture book. PyPDF2 is used to merge the individual PDF files for each page into a single PDF file, and reportlab is used to create the individual PDF files.\n",
       "\n",
       "## Contribution Ideas and Extrapolation to Adjacent Projects\n",
       "\n",
       "FableForge is an open source project, and there are many ways to contribute to it. One idea is to improve the image generation process. Currently, the project uses Replicate for image generation due to its ease of use. However, it is possible to connect it to your own Stable Diffusion setup (local or cloud-based) for better results.\n",
       "\n",
       "Another idea is to add more styles for the picture books. Currently, the project supports several styles, including Impressionism, Cubism, Surrealism, Japanese Ukiyo-e, Art Nouveau, Folk Art, and Expressionism. Adding more styles would provide more options for the users and make the generated books more diverse.\n",
       "\n",
       "This project can also be extrapolated to adjacent projects and work streams. For example, it can be used as a basis for creating a tool for generating comic books or graphic novels. It can also be used to create educational materials, such as illustrated textbooks or educational games. The possibilities are endless."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
